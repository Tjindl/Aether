# âœï¸ Aether â€” AR Whiteboard

> Draw in the air. No pen. No touch. Just your hand.

Aether is a real-time augmented reality whiteboard that tracks your index finger through a webcam and renders strokes directly over your camera feed. Built with MediaPipe Hands and OpenCV, it runs entirely on-device with no internet connection required.

---

## Demo

| Draw | Change Color | Clear |
|------|-------------|-------|
| Extend index finger | âœŒï¸ Peace gesture | âœŠ Fist gesture |

---

## Features

- ðŸ–Šï¸ **Real-time drawing** â€” smooth stroke rendering with EMA jitter smoothing
- ðŸŽ¨ **6 neon colors** â€” cycle through with a gesture
- ðŸ“ **Adjustable brush size** â€” thumbs up / point to resize
- â†©ï¸ **Undo** â€” remove last stroke instantly
- ðŸ§¹ **Clear canvas** â€” wipe everything with a fist
- ðŸ’¾ **Save as PNG** â€” exports to `saved/` folder with timestamp
- ðŸ“· **Camera toggle** â€” switch between AR overlay and pure canvas mode
- âš¡ **Gesture controls** â€” powered by a trained Random Forest classifier (98%+ accuracy)

---

## How It Works

```
Webcam â†’ MediaPipe Hands â†’ Fingertip Position â†’ EMA Smoother â†’ Canvas Renderer
                        â†˜ Gesture Classifier â†’ Action Layer
```

**Drawing detection** uses finger joint geometry â€” index finger extended + middle finger curled = draw mode. No model needed for this, just landmark math.

**Gesture controls** use a Random Forest classifier trained on 63 normalized 3D hand landmark features (21 landmarks Ã— x, y, z), achieving **98.3% test accuracy** across 9 gesture classes.

---

## Gestures

| Gesture | Action |
|---------|--------|
| â˜ï¸ Index finger extended | Draw |
| âœŒï¸ Peace | Cycle colors |
| ðŸ‘ Thumbs up | Brush size + |
| â˜ï¸ Point | Brush size âˆ’ |
| âœŠ Fist | Clear canvas |
| ðŸ¤˜ Rock | Undo last stroke |
| ðŸ‘Œ OK | Save as PNG |
| âœ‹ Open palm | Toggle webcam feed |

---

## Keyboard Shortcuts

| Key | Action |
|-----|--------|
| `Q` | Quit |
| `H` | Toggle landmark overlay |
| `C` | Clear canvas |
| `Z` | Undo |
| `S` | Save canvas |

---

## Installation

**Prerequisites:** Python 3.9+, Apple Silicon Mac (M1/M2/M3)

```bash
# Clone the repo
git clone https://github.com/yourusername/Aether.git
cd Aether

# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install mediapipe-silicon opencv-python-headless numpy scikit-learn
```

> **Note:** Uses `mediapipe-silicon` for Apple Silicon compatibility. On Intel Mac or Linux, replace with `mediapipe`.

---

## Usage

```bash
python aether.py
```

Make sure `gesture_rf.pkl` (the trained gesture model) is in the same directory.

**To draw:**
1. Hold your hand in front of the camera
2. Extend your index finger with middle finger curled down
3. Move your hand â€” strokes follow your fingertip in real time
4. Curl your index finger to pause drawing

---

## Project Structure

```
Aether/
â”œâ”€â”€ aether.py          # Main application
â”œâ”€â”€ gesture_rf.pkl     # Trained gesture classifier
â”œâ”€â”€ saved/             # Exported PNG drawings (auto-created)
â””â”€â”€ README.md
```

---

## Performance

| Setting | Value |
|---------|-------|
| Resolution | 640 Ã— 480 |
| MediaPipe model | Lite (complexity=0) |
| Tip smoothing | EMA Î±=0.35 |
| Min movement threshold | 3px |

Runs at ~30fps on an M-series MacBook with no GPU required.

---

## Tech Stack

- [MediaPipe Hands](https://google.github.io/mediapipe/solutions/hands) â€” hand landmark detection
- [OpenCV](https://opencv.org/) â€” webcam capture and rendering
- [scikit-learn](https://scikit-learn.org/) â€” Random Forest gesture classifier
- [NumPy](https://numpy.org/) â€” landmark normalization and canvas ops

---

## Related Project

The gesture classifier was trained as part of **[Handly](https://github.com/yourusername/Handly)** â€” a real-time gesture controller for macOS system audio and Apple Music.

---

## License

MIT